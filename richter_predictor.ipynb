{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richter's Predictor\n",
    "\n",
    "Initial code is a copy of the example found here: http://drivendata.co/blog/richters-predictor-benchmark/\n",
    "\n",
    "We'll then use an XGBoost model to get a better estimate, and also will look at engineering some features using the geocode.\n",
    "\n",
    "The intention is to try to find a way to use the fact that some areas (geo locations) will have suffered more damage than others.  There seem to be too many level 3 geolocations for a tree-based algorithm to deal with effectively, but if we can somehow uncover information about the geolocation and encode it in a way that is easier for the tree to deal with then it may improve our scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# the model\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, make_scorer\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv(DATA_DIR / 'train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR / 'train_labels.csv', index_col='building_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values  = pd.read_csv(DATA_DIR / 'test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For some feature engineering we want to use the damage grades, so we'll join them here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_values.join(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For others we also want to include test values (eg. when encoding categorical) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_train_values = pd.concat([train_values,test_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             damage_grade\n",
       "building_id              \n",
       "802906                  3\n",
       "28830                   2\n",
       "94947                   3\n",
       "590882                  2\n",
       "201944                  3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_train_values.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_labels.damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['foundation_type', \n",
    "                     'area_percentage', \n",
    "                     'height_percentage',\n",
    "                     'count_floors_pre_eq',\n",
    "                     'land_surface_condition',\n",
    "                     'has_superstructure_cement_mortar_stone']\n",
    "\n",
    "train_values_subset = train_values[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_values_subset.join(train_labels), \n",
    "             hue='damage_grade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_uses = [\n",
    "'has_secondary_use',\n",
    "'has_secondary_use_agriculture',\n",
    "'has_secondary_use_hotel',\n",
    "'has_secondary_use_rental',\n",
    "'has_secondary_use_institution',\n",
    "'has_secondary_use_school',\n",
    "'has_secondary_use_industry',\n",
    "'has_secondary_use_health_post',\n",
    "'has_secondary_use_gov_office',\n",
    "'has_secondary_use_use_police',\n",
    "'has_secondary_use_other'\n",
    "]\n",
    "\n",
    "structure = [\n",
    "'has_superstructure_adobe_mud',\n",
    "'has_superstructure_mud_mortar_stone',\n",
    "'has_superstructure_stone_flag',\n",
    "'has_superstructure_cement_mortar_stone',\n",
    "'has_superstructure_mud_mortar_brick',\n",
    "'has_superstructure_cement_mortar_brick',\n",
    "'has_superstructure_timber',\n",
    "'has_superstructure_bamboo',\n",
    "'has_superstructure_rc_non_engineered',\n",
    "'has_superstructure_rc_engineered',\n",
    "'has_superstructure_other'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for use in secondary_uses:\n",
    "    print(use, train[train[use]==1]['damage_grade'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in structure:\n",
    "    print(s, train[train[s]==1]['damage_grade'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_geo3 = train['geo_level_3_id'].value_counts().head(30).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in biggest_geo3:\n",
    "    print('Geo3 id:',location)\n",
    "    for s in structure:\n",
    "        s_filter = (train['geo_level_3_id'] == location) & (train[s] == 1)\n",
    "        print(s, train.loc[s_filter]['damage_grade'].count(), train.loc[s_filter]['damage_grade'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are similarities in damage between the mortar types (mud/cement) and the reinforced concrete types (non-eng, engineered) so for the sake of our geoid indicator we'll group them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train['mud'] = train['has_superstructure_adobe_mud'] | train['has_superstructure_mud_mortar_stone'] | train['has_superstructure_mud_mortar_brick']\n",
    "train['cement'] = train['has_superstructure_cement_mortar_stone'] | train['has_superstructure_cement_mortar_brick'] \n",
    "train['concrete'] = train['has_superstructure_rc_non_engineered'] | train['has_superstructure_rc_engineered'] \n",
    "train['natural'] = train['has_superstructure_timber'] | train['has_superstructure_bamboo'] \n",
    "\n",
    "test_and_train_values['mud'] = test_and_train_values['has_superstructure_adobe_mud'] | test_and_train_values['has_superstructure_mud_mortar_stone'] | test_and_train_values['has_superstructure_mud_mortar_brick']\n",
    "test_and_train_values['cement'] = test_and_train_values['has_superstructure_cement_mortar_stone'] | test_and_train_values['has_superstructure_cement_mortar_brick'] \n",
    "test_and_train_values['concrete'] = test_and_train_values['has_superstructure_rc_non_engineered'] | test_and_train_values['has_superstructure_rc_engineered'] \n",
    "test_and_train_values['natural'] = test_and_train_values['has_superstructure_timber'] | test_and_train_values['has_superstructure_bamboo'] \n",
    "\n",
    "test_values['mud'] = test_values['has_superstructure_adobe_mud'] | test_values['has_superstructure_mud_mortar_stone'] | test_values['has_superstructure_mud_mortar_brick']\n",
    "test_values['cement'] = test_values['has_superstructure_cement_mortar_stone'] | test_values['has_superstructure_cement_mortar_brick'] \n",
    "test_values['concrete'] = test_values['has_superstructure_rc_non_engineered'] | test_values['has_superstructure_rc_engineered'] \n",
    "test_values['natural'] = test_values['has_superstructure_timber'] | test_values['has_superstructure_bamboo'] \n",
    "\n",
    "train['n_struc_types'] = train['mud'] + train['cement'] + train['concrete'] + train['natural']\n",
    "test_and_train_values['n_struc_types'] = test_and_train_values['mud'] + test_and_train_values['cement'] + test_and_train_values['concrete'] + test_and_train_values['natural']\n",
    "test_values['n_struc_types'] = test_values['mud'] + test_values['cement'] + test_values['concrete'] + test_values['natural']\n",
    "\n",
    "train['concrete_only'] = (train['concrete']==True) & (train['n_struc_types']==1)\n",
    "train['cement_only'] = (train['cement']==True) & (train['n_struc_types']==1)\n",
    "\n",
    "test_and_train_values['concrete_only'] = (test_and_train_values['concrete']==True) & (test_and_train_values['n_struc_types']==1)\n",
    "test_and_train_values['cement_only'] = (test_and_train_values['cement']==True) & (test_and_train_values['n_struc_types']==1)\n",
    "\n",
    "test_values['concrete_only'] = (test_values['concrete']==True) & (test_values['n_struc_types']==1)\n",
    "test_values['cement_only'] = (test_values['cement']==True) & (test_values['n_struc_types']==1)\n",
    "\n",
    "# This next one is just a helper column for use later to get averages of damage for each region\n",
    "train['no-mud'] = abs(train['mud']-1)\n",
    "test_and_train_values['no-mud'] = abs(test_and_train_values['mud']-1)\n",
    "test_values['no-mud'] = abs(test_values['mud']-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_only = (train['concrete']==True) & (train['n_struc_types']==1)\n",
    "mud_only = (train['mud']==True) & (train['n_struc_types']==1)\n",
    "cement_only = (train['cement']==True) & (train['n_struc_types']==1)\n",
    "natural_only = (train['natural']==True) & (train['n_struc_types']==1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations about the building types:\n",
    "* If building has some mud, damage is at least 2\n",
    "* The distribution of damage isn't materially different whether the building is all mud or just has some mud.\n",
    "* All-concrete buildings suffer very little damage\n",
    "* All-cement are also strong, but not quite as good as all-concrete\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['mud']==True].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of mud Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[mud_only].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of mud only Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['mud']==False].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of non-mud Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['natural']==True].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of natural Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[natural_only].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of natural only Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[train['cement']==True].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of cement Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[cement_only].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of cement only Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[(train['concrete']==True)].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of concrete Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(train[concrete_only].damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of concrete only Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struc_types = ['mud','natural','cement','concrete']\n",
    "combs = []\n",
    "for i in range(len(struc_types)):\n",
    "    combs.extend([list(t) for t in [k for k in itertools.combinations(struc_types,i+1)]])\n",
    "    \n",
    "combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [train[t]==True for t in combs[12]]\n",
    "train[np.logical_and.reduce(filters)].damage_grade.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logical_and.reduce(filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in combs:\n",
    "    filters = [train[t]==True for t in c]\n",
    "    print(c)\n",
    "    print(train[np.logical_and.reduce(filters)].damage_grade\n",
    "             .mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[list(t) for t in [k for k in itertools.combinations(struc_types,2)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some geolocations might only be in the test set, so if we are going to build a universal lookup then we need to include test as well so we can get a complete list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_train_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_and_train.head()\n",
    "test_and_train_values.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_lookup = test_and_train_values[['geo_level_3_id','geo_level_2_id','geo_level_1_id']].groupby(['geo_level_3_id']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1061</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_3_id  geo_level_2_id  geo_level_1_id\n",
       "0               0             179              12\n",
       "1               1             194              15\n",
       "2               2             657               0\n",
       "3               3              73              30\n",
       "4               4            1061               5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OK, now we can calcualte averages for each geoid level and construction type, and build our lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm going to double check what the frequency is like for the different structure types, because I'm worried that we won't have many examples of concrete and if that is an issue then we need to account for it somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['1','2','3']\n",
    "structure_cats = ['mud','no-mud','cement_only', 'concrete_only']\n",
    "\n",
    "\n",
    "# plot\n",
    "f, axes = plt.subplots(1, 4, figsize=(14, 4), sharex=True, sharey=True)\n",
    "\n",
    "# Change the x-axis because it has a really long tail.  First attempt was to make it log, second just trims\n",
    "#axes[0,0].set(xscale=\"log\")\n",
    "axes[0].set_xlim(right=20)\n",
    "\n",
    "graph_colours = ['skyblue','olive', 'gold', 'teal']\n",
    "ax = [axes[0],axes[1],axes[2],axes[3]]\n",
    "\n",
    "for i,s in enumerate(structure_cats):\n",
    "    sns.distplot( geo_lookup[s+'1_n'].fillna(0) , color=graph_colours[i], ax=ax[i], bins=300)\n",
    "\n",
    "#################################\n",
    "f, axes = plt.subplots(1, 4, figsize=(14, 4), sharex=True, sharey=True)\n",
    "\n",
    "# Change the x-axis because it has a really long tail.  First attempt was to make it log, second just trims\n",
    "#axes[0,0].set(xscale=\"log\")\n",
    "axes[0].set_xlim(right=20)\n",
    "\n",
    "graph_colours = ['skyblue','olive', 'gold', 'teal']\n",
    "ax = [axes[0],axes[1],axes[2],axes[3]]\n",
    "\n",
    "for i,s in enumerate(structure_cats):\n",
    "    sns.distplot( geo_lookup[s+'2_n'].fillna(0) , color=graph_colours[i], ax=ax[i], bins=300)\n",
    "\n",
    "\n",
    "#################################\n",
    "f, axes = plt.subplots(2, 2, figsize=(7, 7), sharex=True, sharey=True)\n",
    "\n",
    "# Change the x-axis because it has a really long tail.  First attempt was to make it log, second just trims\n",
    "#axes[0,0].set(xscale=\"log\")\n",
    "axes[0,0].set_xlim(right=20)\n",
    "\n",
    "graph_colours = ['skyblue','olive', 'gold', 'teal']\n",
    "ax = [axes[0, 0],axes[0, 1],axes[1, 0],axes[1, 1]]\n",
    "\n",
    "\n",
    "for i,s in enumerate(structure_cats):\n",
    "    sns.distplot( geo_lookup[s+'3_n'].fillna(0) , color=graph_colours[i], ax=ax[i], bins=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_cats = ['mud','natural', 'cement', 'concrete']\n",
    "\n",
    "for location in biggest_geo3:\n",
    "    print('Geo3 id:',location)\n",
    "    for s in structure_cats:\n",
    "        s_filter = (train['geo_level_3_id'] == location) & (train[s] == 1)\n",
    "        print(s, train.loc[s_filter]['damage_grade'].count(), train.loc[s_filter]['damage_grade'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = {}\n",
    "levels = ['1','2','3']\n",
    "for level in levels:\n",
    "    for s in structure_cats:\n",
    "        s_filter = train[s] == 1\n",
    "        averages[s+level] = train[s_filter].groupby('geo_level_'+level+'_id')['damage_grade'].agg({s+level+'_n':'count', \n",
    "                                     s+level+'_mean':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages['mud1'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.merge(averages['mud2'].reset_index(), how='left',on='geo_level_2_id').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Everything is looking OK, let's do it again but this time merge inline rather than saving to a dictionary first\n",
    "We use train here because that df has got the damage values in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging level 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "averaging level 2\n",
      "averaging level 3\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "levels = ['1','2','3']\n",
    "structure_cats = ['mud','no-mud','cement_only', 'concrete_only']\n",
    "\n",
    "\n",
    "for level in levels:\n",
    "    print('averaging level',level)\n",
    "    averages_list = []\n",
    "\n",
    "    # Work out normalised damage grades for each structure type\n",
    "    for s in structure_cats:\n",
    "        s_filter = train[s] == 1\n",
    "        averages = train[s_filter].groupby('geo_level_'+level+'_id')['damage_grade'].agg({s+level+'_n':'count', \n",
    "                                     s+level+'_mean':'mean'})\n",
    "        col_to_norm = averages[s+level+'_mean']\n",
    "        averages[s+level+'_mean_norm']=(col_to_norm-col_to_norm.min())/(col_to_norm.max()-col_to_norm.min())\n",
    "        #print(averages.head(2))\n",
    "        averages_list.append(averages)\n",
    "\n",
    "    # Concat the averages into one dataframe\n",
    "    averages = pd.concat(averages_list, axis=1)\n",
    "    #print(averages.head())\n",
    "    #print(geo_lookup.shape)\n",
    "    \n",
    "    # Now we have those, we can also calculate a weighted average across the structure types for that geoid\n",
    "    \n",
    "    cols = [s+level+'_mean_norm' for s in structure_cats]\n",
    "    weights = [s+level+'_n' for s in structure_cats]\n",
    "\n",
    "    norms_np = averages[cols].values\n",
    "    weights_np = averages[weights].values\n",
    "\n",
    "    norm_mask = np.isnan(norms_np)\n",
    "    weights_mask = np.isnan(weights_np)\n",
    "\n",
    "    norms_np = np.ma.masked_array(norms_np, mask=norm_mask)\n",
    "    weights_np = np.ma.masked_array(weights_np, mask=weights_mask)\n",
    "\n",
    "    wa_norm = np.ma.average(norms_np, weights=weights_np, axis=1)\n",
    "    wa_norm.fill_value = -1\n",
    "    averages['level'+level+'norm_damage'] = wa_norm.filled()\n",
    "    #geo_lookup['level'+level+'_wa_norm_damage'] = wa_norm.filled()\n",
    "    #print(averages.head())\n",
    "    \n",
    "    # Add on the columns we want to keep after all of that\n",
    "    geo_lookup = geo_lookup.merge(averages['level'+level+'norm_damage'].reset_index(), how='left',on='geo_level_'+level+'_id')\n",
    "    geo_lookup = geo_lookup.merge(averages['mud'+level+'_mean_norm'].reset_index(), how='left',on='geo_level_'+level+'_id')\n",
    "    geo_lookup = geo_lookup.merge(averages['no-mud'+level+'_mean_norm'].reset_index(), how='left',on='geo_level_'+level+'_id')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some  geoids have missing values though, presumably because the only examples are in the training set.  So we can use the next available level up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_level_3_id       8800.000000\n",
       "geo_level_2_id        295.000000\n",
       "geo_level_1_id         28.000000\n",
       "level1norm_damage       0.549266\n",
       "mud1_mean_norm          0.536741\n",
       "no-mud1_mean_norm       0.905540\n",
       "level2norm_damage            NaN\n",
       "mud2_mean_norm               NaN\n",
       "no-mud2_mean_norm            NaN\n",
       "level3norm_damage            NaN\n",
       "mud3_mean_norm               NaN\n",
       "no-mud3_mean_norm            NaN\n",
       "Name: 8313, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_lookup.loc[8313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_level = geo_lookup['level2norm_damage'].isnull()\n",
    "geo_lookup.loc[empty_level,'level2norm_damage'] = geo_lookup.loc[empty_level,'level1norm_damage']\n",
    "\n",
    "empty_level = geo_lookup['level3norm_damage'].isnull()\n",
    "geo_lookup.loc[empty_level,'level3norm_damage'] = geo_lookup.loc[empty_level,'level2norm_damage']\n",
    "\n",
    "\n",
    "empty_level = geo_lookup['mud2_mean_norm'].isnull()\n",
    "geo_lookup.loc[empty_level,'mud2_mean_norm'] = geo_lookup.loc[empty_level,'mud1_mean_norm']\n",
    "\n",
    "empty_level = geo_lookup['mud3_mean_norm'].isnull()\n",
    "geo_lookup.loc[empty_level,'mud3_mean_norm'] = geo_lookup.loc[empty_level,'mud2_mean_norm']\n",
    "\n",
    "\n",
    "empty_level = geo_lookup['no-mud2_mean_norm'].isnull()\n",
    "geo_lookup.loc[empty_level,'no-mud2_mean_norm'] = geo_lookup.loc[empty_level,'no-mud1_mean_norm']\n",
    "\n",
    "empty_level = geo_lookup['no-mud3_mean_norm'].isnull()\n",
    "geo_lookup.loc[empty_level,'no-mud3_mean_norm'] = geo_lookup.loc[empty_level,'no-mud2_mean_norm']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_level_3_id       8800.000000\n",
       "geo_level_2_id        295.000000\n",
       "geo_level_1_id         28.000000\n",
       "level1norm_damage       0.549266\n",
       "mud1_mean_norm          0.536741\n",
       "no-mud1_mean_norm       0.905540\n",
       "level2norm_damage       0.549266\n",
       "mud2_mean_norm          0.536741\n",
       "no-mud2_mean_norm       0.905540\n",
       "level3norm_damage       0.549266\n",
       "mud3_mean_norm          0.536741\n",
       "no-mud3_mean_norm       0.905540\n",
       "Name: 8313, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_lookup.loc[8313]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, join the lookup table with the test/train values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_train_values = test_and_train_values.merge(geo_lookup[['geo_level_3_id','level3norm_damage','mud3_mean_norm','no-mud3_mean_norm']], on=['geo_level_3_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cement</th>\n",
       "      <th>concrete</th>\n",
       "      <th>natural</th>\n",
       "      <th>n_struc_types</th>\n",
       "      <th>concrete_only</th>\n",
       "      <th>cement_only</th>\n",
       "      <th>no-mud</th>\n",
       "      <th>level3norm_damage</th>\n",
       "      <th>mud3_mean_norm</th>\n",
       "      <th>no-mud3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22011</th>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>3238</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.224731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22012</th>\n",
       "      <td>8</td>\n",
       "      <td>600</td>\n",
       "      <td>3238</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.224731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22013</th>\n",
       "      <td>17</td>\n",
       "      <td>1149</td>\n",
       "      <td>4221</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22014</th>\n",
       "      <td>17</td>\n",
       "      <td>1149</td>\n",
       "      <td>4221</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
       "22011               8             600            3238                    2   \n",
       "22012               8             600            3238                    2   \n",
       "22013              17            1149            4221                    3   \n",
       "22014              17            1149            4221                    2   \n",
       "\n",
       "       age  area_percentage  height_percentage land_surface_condition  \\\n",
       "22011    5               12                  8                      t   \n",
       "22012   30                6                  8                      t   \n",
       "22013   30                5                  7                      t   \n",
       "22014   10                7                  5                      t   \n",
       "\n",
       "      foundation_type roof_type  ... cement concrete natural n_struc_types  \\\n",
       "22011               r         n  ...      0        0       0             1   \n",
       "22012               r         n  ...      0        0       0             1   \n",
       "22013               r         n  ...      0        0       1             2   \n",
       "22014               r         n  ...      0        0       1             2   \n",
       "\n",
       "       concrete_only  cement_only  no-mud  level3norm_damage  mud3_mean_norm  \\\n",
       "22011          False        False       0           0.875000           0.875   \n",
       "22012          False        False       0           0.875000           0.875   \n",
       "22013          False        False       0           0.989899           1.000   \n",
       "22014          False        False       0           0.989899           1.000   \n",
       "\n",
       "       no-mud3_mean_norm  \n",
       "22011           0.224731  \n",
       "22012           0.224731  \n",
       "22013           0.500000  \n",
       "22014           0.500000  \n",
       "\n",
       "[4 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_and_train_values[22011:22015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the categorical into numeric\n",
    "\n",
    "This code taken from https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "\n",
    "categorical_encoder = defaultdict(LabelEncoder)\n",
    "\n",
    "'# Encoding the variable\n",
    "\n",
    "fit = df.apply(lambda x: categorical_encoder[x.name].fit_transform(x))\n",
    "\n",
    "'# Inverse the encoded\n",
    "\n",
    "fit.apply(lambda x: categorical_encoder[x.name].inverse_transform(x))\n",
    "\n",
    "'# Using the dictionary to label future data\n",
    "\n",
    "df.apply(lambda x: categorical_encoder[x.name].transform(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'land_surface_condition',\n",
    "    'foundation_type',\n",
    "    'roof_type',\n",
    "    'ground_floor_type',\n",
    "    'other_floor_type',\n",
    "    'position',\n",
    "    'plan_configuration',\n",
    "    'legal_ownership_status'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoder = defaultdict(LabelEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the encoder on the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_train_values.loc[:,categorical_columns] = test_and_train_values.loc[:,categorical_columns].apply(lambda x: categorical_encoder[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cement</th>\n",
       "      <th>concrete</th>\n",
       "      <th>natural</th>\n",
       "      <th>n_struc_types</th>\n",
       "      <th>concrete_only</th>\n",
       "      <th>cement_only</th>\n",
       "      <th>no-mud</th>\n",
       "      <th>level3norm_damage</th>\n",
       "      <th>mud3_mean_norm</th>\n",
       "      <th>no-mud3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  age  \\\n",
       "0               6             487           12198                    2   30   \n",
       "1               6             487           12198                    2   15   \n",
       "2               6             487           12198                    2   80   \n",
       "3               6             487           12198                    2   20   \n",
       "4               6             487           12198                    2   20   \n",
       "\n",
       "   area_percentage  height_percentage  land_surface_condition  \\\n",
       "0                6                  5                       2   \n",
       "1                3                  5                       2   \n",
       "2                6                  5                       2   \n",
       "3               10                  5                       2   \n",
       "4                3                  5                       2   \n",
       "\n",
       "   foundation_type  roof_type  ...  cement  concrete  natural  n_struc_types  \\\n",
       "0                2          0  ...       0         0        0              1   \n",
       "1                2          0  ...       0         0        0              1   \n",
       "2                2          0  ...       0         0        0              1   \n",
       "3                2          0  ...       0         0        0              1   \n",
       "4                2          0  ...       0         0        0              1   \n",
       "\n",
       "   concrete_only  cement_only  no-mud  level3norm_damage  mud3_mean_norm  \\\n",
       "0          False        False       0           0.918919        0.918919   \n",
       "1          False        False       0           0.918919        0.918919   \n",
       "2          False        False       0           0.918919        0.918919   \n",
       "3          False        False       0           0.918919        0.918919   \n",
       "4          False        False       0           0.918919        0.918919   \n",
       "\n",
       "   no-mud3_mean_norm  \n",
       "0           0.416667  \n",
       "1           0.416667  \n",
       "2           0.416667  \n",
       "3           0.416667  \n",
       "4           0.416667  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_and_train_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the encoder to transform the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.loc[:,categorical_columns] = train_values.loc[:,categorical_columns].apply(lambda x: categorical_encoder[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_level_1_id                            int64\n",
       "geo_level_2_id                            int64\n",
       "geo_level_3_id                            int64\n",
       "count_floors_pre_eq                       int64\n",
       "age                                       int64\n",
       "area_percentage                           int64\n",
       "height_percentage                         int64\n",
       "land_surface_condition                    int32\n",
       "foundation_type                           int32\n",
       "roof_type                                 int32\n",
       "ground_floor_type                         int32\n",
       "other_floor_type                          int32\n",
       "position                                  int32\n",
       "plan_configuration                        int32\n",
       "has_superstructure_adobe_mud              int64\n",
       "has_superstructure_mud_mortar_stone       int64\n",
       "has_superstructure_stone_flag             int64\n",
       "has_superstructure_cement_mortar_stone    int64\n",
       "has_superstructure_mud_mortar_brick       int64\n",
       "has_superstructure_cement_mortar_brick    int64\n",
       "has_superstructure_timber                 int64\n",
       "has_superstructure_bamboo                 int64\n",
       "has_superstructure_rc_non_engineered      int64\n",
       "has_superstructure_rc_engineered          int64\n",
       "has_superstructure_other                  int64\n",
       "legal_ownership_status                    int32\n",
       "count_families                            int64\n",
       "has_secondary_use                         int64\n",
       "has_secondary_use_agriculture             int64\n",
       "has_secondary_use_hotel                   int64\n",
       "has_secondary_use_rental                  int64\n",
       "has_secondary_use_institution             int64\n",
       "has_secondary_use_school                  int64\n",
       "has_secondary_use_industry                int64\n",
       "has_secondary_use_health_post             int64\n",
       "has_secondary_use_gov_office              int64\n",
       "has_secondary_use_use_police              int64\n",
       "has_secondary_use_other                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "      <th>mud</th>\n",
       "      <th>cement</th>\n",
       "      <th>concrete</th>\n",
       "      <th>natural</th>\n",
       "      <th>n_struc_types</th>\n",
       "      <th>concrete_only</th>\n",
       "      <th>cement_only</th>\n",
       "      <th>no-mud</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802906</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94947</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590882</th>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201944</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_level_1_id  geo_level_2_id  geo_level_3_id  \\\n",
       "building_id                                                   \n",
       "802906                    6             487           12198   \n",
       "28830                     8             900            2812   \n",
       "94947                    21             363            8973   \n",
       "590882                   22             418           10694   \n",
       "201944                   11             131            1488   \n",
       "\n",
       "             count_floors_pre_eq  age  area_percentage  height_percentage  \\\n",
       "building_id                                                                 \n",
       "802906                         2   30                6                  5   \n",
       "28830                          2   10                8                  7   \n",
       "94947                          2   10                5                  5   \n",
       "590882                         2   10                6                  5   \n",
       "201944                         3   30                8                  9   \n",
       "\n",
       "            land_surface_condition foundation_type roof_type  ...  \\\n",
       "building_id                                                   ...   \n",
       "802906                           t               r         n  ...   \n",
       "28830                            o               r         n  ...   \n",
       "94947                            t               r         n  ...   \n",
       "590882                           t               r         n  ...   \n",
       "201944                           t               r         n  ...   \n",
       "\n",
       "            has_secondary_use_other damage_grade mud cement  concrete  \\\n",
       "building_id                                                             \n",
       "802906                            0            3   1      0         0   \n",
       "28830                             0            2   1      0         0   \n",
       "94947                             0            3   1      0         0   \n",
       "590882                            0            2   1      0         0   \n",
       "201944                            0            3   1      0         0   \n",
       "\n",
       "             natural  n_struc_types  concrete_only  cement_only  no-mud  \n",
       "building_id                                                              \n",
       "802906             0              1          False        False       0  \n",
       "28830              0              1          False        False       0  \n",
       "94947              0              1          False        False       0  \n",
       "590882             1              2          False        False       0  \n",
       "201944             0              1          False        False       0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features are now categorical so we could use them on a classifier now, but...let's engineer some features first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(geo_lookup[['geo_level_3_id','level3norm_damage','mud3_mean_norm','no-mud3_mean_norm']], on=['geo_level_3_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,categorical_columns] = train.loc[:,categorical_columns].apply(lambda x: categorical_encoder[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cement</th>\n",
       "      <th>concrete</th>\n",
       "      <th>natural</th>\n",
       "      <th>n_struc_types</th>\n",
       "      <th>concrete_only</th>\n",
       "      <th>cement_only</th>\n",
       "      <th>no-mud</th>\n",
       "      <th>level3norm_damage</th>\n",
       "      <th>mud3_mean_norm</th>\n",
       "      <th>no-mud3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.771127</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.690265</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  age  \\\n",
       "0               6             487           12198                    2   30   \n",
       "1               8             900            2812                    2   10   \n",
       "2              21             363            8973                    2   10   \n",
       "3              22             418           10694                    2   10   \n",
       "4              11             131            1488                    3   30   \n",
       "\n",
       "   area_percentage  height_percentage  land_surface_condition  \\\n",
       "0                6                  5                       2   \n",
       "1                8                  7                       1   \n",
       "2                5                  5                       2   \n",
       "3                6                  5                       2   \n",
       "4                8                  9                       2   \n",
       "\n",
       "   foundation_type  roof_type  ...  cement  concrete  natural  n_struc_types  \\\n",
       "0                2          0  ...       0         0        0              1   \n",
       "1                2          0  ...       0         0        0              1   \n",
       "2                2          0  ...       0         0        0              1   \n",
       "3                2          0  ...       0         0        1              2   \n",
       "4                2          0  ...       0         0        0              1   \n",
       "\n",
       "   concrete_only  cement_only  no-mud  level3norm_damage  mud3_mean_norm  \\\n",
       "0          False        False       0           0.918919        0.918919   \n",
       "1          False        False       0           0.500000        0.566667   \n",
       "2          False        False       0           0.771127        0.820312   \n",
       "3          False        False       0           0.548387        0.571429   \n",
       "4          False        False       0           0.680000        0.690265   \n",
       "\n",
       "   no-mud3_mean_norm  \n",
       "0           0.416667  \n",
       "1           0.000000  \n",
       "2           0.312500  \n",
       "3           0.333333  \n",
       "4           0.611111  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep the test data too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = test_values.merge(geo_lookup[['geo_level_3_id','level3norm_damage','mud3_mean_norm','no-mud3_mean_norm']], on=['geo_level_3_id'], how='left')\n",
    "test_values.loc[:,categorical_columns] = test_values.loc[:,categorical_columns].apply(lambda x: categorical_encoder[x.name].transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>...</th>\n",
       "      <th>cement</th>\n",
       "      <th>concrete</th>\n",
       "      <th>natural</th>\n",
       "      <th>n_struc_types</th>\n",
       "      <th>concrete_only</th>\n",
       "      <th>cement_only</th>\n",
       "      <th>no-mud</th>\n",
       "      <th>level3norm_damage</th>\n",
       "      <th>mud3_mean_norm</th>\n",
       "      <th>no-mud3_mean_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>596</td>\n",
       "      <td>11307</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>11987</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.021434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10044</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>633</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.211715</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>289</td>\n",
       "      <td>7970</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  age  \\\n",
       "0              17             596           11307                    3   20   \n",
       "1               6             141           11987                    2   25   \n",
       "2              22              19           10044                    2    5   \n",
       "3              26              39             633                    1    0   \n",
       "4              17             289            7970                    3   15   \n",
       "\n",
       "   area_percentage  height_percentage  land_surface_condition  \\\n",
       "0                7                  6                       2   \n",
       "1               13                  5                       2   \n",
       "2                4                  5                       2   \n",
       "3               19                  3                       2   \n",
       "4                8                  7                       2   \n",
       "\n",
       "   foundation_type  roof_type  ...  cement  concrete  natural  n_struc_types  \\\n",
       "0                2          0  ...       0         0        0              1   \n",
       "1                2          0  ...       0         0        0              1   \n",
       "2                2          0  ...       0         0        0              1   \n",
       "3                2          2  ...       1         0        0              1   \n",
       "4                2          1  ...       0         0        0              1   \n",
       "\n",
       "   concrete_only  cement_only  no-mud  level3norm_damage  mud3_mean_norm  \\\n",
       "0          False        False       0           0.775000        0.861111   \n",
       "1          False        False       0           0.500000        0.500000   \n",
       "2          False        False       0           1.000000        1.000000   \n",
       "3          False         True       1           0.211715        0.428571   \n",
       "4          False        False       0           0.911765        0.911765   \n",
       "\n",
       "   no-mud3_mean_norm  \n",
       "0           0.000000  \n",
       "1           0.021434  \n",
       "2           0.555556  \n",
       "3           0.214286  \n",
       "4           0.478261  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damage measures for each geolocation\n",
    "\n",
    "The idae here is that I want a normalised measure of average damage per geolocation.  The easiest way would be to take the average damage value for the geoid but that wouldn't take into consideration the different mix of building types.  If some geolocations had sturdier buildings then it's average damage might be artifically low.\n",
    "\n",
    "So instead I'll take the average damage for each building type and/or some sort of adjustment for the building type - for example wooden buildings seem to have less damage so perhaps we can work out some normalised values for each building type and then combine them to get a single normalised damage value for each geoid.\n",
    "\n",
    "The last factor I want to allow for is that some geoids have only one data point, and that isn't gong to be of much use, so instead my intial approach will be to take the average of the next geolevel up if the count of datapoints is below a certain threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ex_geo = train.drop(['geo_level_1_id','geo_level_2_id','geo_level_3_id', 'damage_grade'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=0.0 should be either positive and smaller than the number of samples 260601 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-2c53dec3b239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ex_geo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'damage_grade'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[1;32m-> 2100\u001b[1;33m                                               default_test_size=0.25)\n\u001b[0m\u001b[0;32m   2101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   1732\u001b[0m         raise ValueError('test_size={0} should be either positive and smaller'\n\u001b[0;32m   1733\u001b[0m                          \u001b[1;34m' than the number of samples {1} or a float in the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1734\u001b[1;33m                          '(0, 1) range'.format(test_size, n_samples))\n\u001b[0m\u001b[0;32m   1735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m     if (train_size_type == 'i' and (train_size >= n_samples or train_size <= 0)\n",
      "\u001b[1;31mValueError\u001b[0m: test_size=0.0 should be either positive and smaller than the number of samples 260601 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_ex_geo, train['damage_grade'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.45325648, 0.5860361 , 0.99597749])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15)#, class_weight='balanced')\n",
    "%time clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('count_floors_pre_eq', 0.00860797604506305), ('age', 0.024078855981554213), ('area_percentage', 0.018755029289347438), ('height_percentage', 0.012444850373930281), ('land_surface_condition', 0.0036683989122530216), ('foundation_type', 0.0164092968207304), ('roof_type', 0.01477704444674699), ('ground_floor_type', 0.008777247225774446), ('other_floor_type', 0.006845643065923988), ('position', 0.006244861553027502), ('plan_configuration', 0.0035167512239424486), ('has_superstructure_adobe_mud', 0.0023723243970389047), ('has_superstructure_mud_mortar_stone', 0.012363182383059996), ('has_superstructure_stone_flag', 0.003545343557448163), ('has_superstructure_cement_mortar_stone', 0.0015558797174324854), ('has_superstructure_mud_mortar_brick', 0.0024425276734939944), ('has_superstructure_cement_mortar_brick', 0.006927610654331409), ('has_superstructure_timber', 0.0025129516523753506), ('has_superstructure_bamboo', 0.0020077917183965103), ('has_superstructure_rc_non_engineered', 0.0021446586655190164), ('has_superstructure_rc_engineered', 0.002983696269081748), ('has_superstructure_other', 0.0013955672889073329), ('legal_ownership_status', 0.0029295275604742364), ('count_families', 0.006542640704830408), ('has_secondary_use', 0.0033106698324447156), ('has_secondary_use_agriculture', 0.0016430746685094854), ('has_secondary_use_hotel', 0.0019997230783063385), ('has_secondary_use_rental', 0.0008776439923378689), ('has_secondary_use_institution', 0.00020276238326044212), ('has_secondary_use_school', 0.000119991492093067), ('has_secondary_use_industry', 0.00027437618689679286), ('has_secondary_use_health_post', 3.8187583100884253e-05), ('has_secondary_use_gov_office', 4.774333520918452e-05), ('has_secondary_use_use_police', 1.7145717680643425e-05), ('has_secondary_use_other', 0.0006411148221523216), ('mud', 0.03239169393510025), ('cement', 0.008168606363394768), ('concrete', 0.00583339647389235), ('natural', 0.0028128129173272277), ('n_struc_types', 0.005165697296870668), ('concrete_only', 0.005748616237036304), ('cement_only', 0.002718641188401591), ('no-mud', 0.026713939786123242), ('level3norm_damage', 0.3005856320946624), ('mud3_mean_norm', 0.34499524443513774), ('no-mud3_mean_norm', 0.08184362899937864)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(X_train.columns,clf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.763300780875271"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on full dataset and predict probabilities so we can combine predictions across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(train_ex_geo, train['damage_grade']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only a few of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use = [\n",
    "    'level3norm_damage',\n",
    "    'mud3_mean_norm',\n",
    "    'no-mud3_mean_norm',\n",
    "    'mud',\n",
    "    'cement_only',\n",
    "    'concrete_only',\n",
    "    'count_floors_pre_eq',\n",
    "    'age',\n",
    "    'foundation_type',\n",
    "    'roof_type',\n",
    "    'area_percentage',\n",
    "    'height_percentage',\n",
    "    'ground_floor_type'\n",
    "]\n",
    "\n",
    "train_select_cols = train[cols_to_use]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_select_cols, train['damage_grade'], test_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=500, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15, class_weight='balanced')\n",
    "%time clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('level3norm_damage', 0.32878705661530355), ('mud3_mean_norm', 0.2738372185163805), ('no-mud3_mean_norm', 0.08035920970682948), ('mud', 0.09976088984060352), ('cement_only', 0.007266542823358438), ('concrete_only', 0.0053637664521563565), ('count_floors_pre_eq', 0.013061008514811545), ('age', 0.04032687459466875), ('foundation_type', 0.03902052369355685), ('roof_type', 0.04266654539100031), ('area_percentage', 0.02643652760677033), ('height_percentage', 0.0179941543292392), ('ground_floor_type', 0.025119681915321202)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(X_train.columns,clf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7325982962830319"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3065,   626,    77],\n",
       "       [ 2549, 15684,  4068],\n",
       "       [  203,  2930,  9889]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = RandomForestClassifier(n_estimators=500, max_depth=15)#, class_weight='balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf1.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626484526390513"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train on full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 18s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf1.fit(train_select_cols, train['damage_grade']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2696,  2279,    39],\n",
       "       [  895, 25529,  3305],\n",
       "       [   66,  5787, 11525]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=500, max_depth=15, class_weight={1:1.5,2:1,3:1.2})\n",
    "%time clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfLD = LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')\n",
    "%time clfLD.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predLD = clfLD.predict(X_test)\n",
    "f1_score(y_test, y_predLD, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_k = KNeighborsClassifier(15)\n",
    "%time clf_k.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_k = clf_k.predict(X_test)\n",
    "f1_score(y_test, y_pred_k, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, now let's try that with XGBoost on the smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train-1)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "param = {'max_depth':6, 'eta':0.3, 'subsample':1, 'objective':'multi:softmax', 'num_class':3 }\n",
    "num_round = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%time bst = xgb.train(param, dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "y_predXG = bst.predict(dtest) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615563684735618"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predXG, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "dtrain_full = xgb.DMatrix(train_select_cols, label=train['damage_grade']-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clfXGB = xgb.train(param, dtrain_full, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predXG[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predLD[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And XGBoost on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_ex_geo, train['damage_grade'], test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train-1)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters via map\n",
    "param = {'max_depth':10, 'eta':0.3, 'subsample':1, 'objective':'multi:softmax', 'num_class':3 }\n",
    "num_round = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%time bst = xgb.train(param, dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "y_predXG = bst.predict(dtest) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7578135492411888"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predXG, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_ex_geo, train['damage_grade'], test_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also try imbalance XGBoost\n",
    "Can't get past the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imxgboost.imbalance_xgb import imbalance_xgboost as imb_xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import LeaveOneOut , cross_validate\n",
    "\n",
    "# focal XGBoost\n",
    "xgboster_focal = imb_xgb(special_objective='focal')\n",
    "# cross - validation booster\n",
    "CV_focal_booster = GridSearchCV ( xgboster_focal , {\"focal_gamma\":[1.0 , 2.0 , 3.0]})\n",
    "# fit the booster\n",
    "CV_focal_booster . fit (X_train.values , y_train.values )\n",
    "# retrieve the best model and parameter\n",
    "opt_focal_booster = CV_focal_booster . best_estimator_\n",
    "opt_focal_parameter = CV_focal_booster . best_params_\n",
    "# instantialize an imbalance - xgboost instance for cross - validation\n",
    "xgboost_focal_opt = imb_xgb (special_objective='focal', ** xgboost_opt_param )\n",
    "# initialize a leave -one splitter\n",
    "loo_splitter = LeaveOneOut ()\n",
    "# Leave - One cross validation\n",
    "loo_info_dict = cross_validate ( xgboost_focal_opt , X=X_train , y=y_train-1 , cv= loo_splitter )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try grid search with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.3, n_estimators=600, objective='multi:softmax',\n",
    "                    silent=False, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "    'max_depth' : [5,7,10,13],\n",
    "#    'gamma': [0, 0.2],\n",
    "#    'subsample': [0.8, 1],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_micro = make_scorer(f1_score, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed: 12.4min remaining: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed: 17.6min remaining: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed: 17.7min remaining: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed: 38.9min remaining: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed: 39.0min remaining: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 49.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed: 49.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([ 680.77142072,  924.62758875, 1371.92149425, 1580.45342934]), 'std_fit_time': array([0.6926322 , 0.85582471, 2.76796508, 0.13457549]), 'mean_score_time': array([ 55.06488824, 126.46534002, 219.58772242, 309.9591856 ]), 'std_score_time': array([0.86261225, 0.58913696, 0.93315852, 0.84317327]), 'param_max_depth': masked_array(data=[5, 7, 10, 13],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 5}, {'max_depth': 7}, {'max_depth': 10}, {'max_depth': 13}], 'split0_test_score': array([0.75405174, 0.74564579, 0.73112726, 0.72192678]), 'split1_test_score': array([0.75479211, 0.74677441, 0.72987224, 0.72446391]), 'mean_test_score': array([0.75442192, 0.7462101 , 0.73049975, 0.72319534]), 'std_test_score': array([0.00037019, 0.00056431, 0.00062751, 0.00126857]), 'rank_test_score': array([1, 2, 3, 4])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=None, n_estimators=600, n_jobs=1,\n",
      "              nthread=1, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=False, subsample=1, verbosity=1)\n",
      "\n",
      " Best score:\n",
      "0.5088438445216921\n",
      "\n",
      " Best parameters:\n",
      "{'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=xgb, param_grid=grid_params, scoring=f1_micro, n_jobs=-1, cv=2, verbose=10 )\n",
    "grid.fit(X_train, y_train-1)\n",
    "print('\\n All results:')\n",
    "print(grid.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(grid.best_estimator_)\n",
    "print('\\n Best score:')\n",
    "print(grid.best_score_ * 2 - 1)\n",
    "print('\\n Best parameters:')\n",
    "print(grid.best_params_)\n",
    "results = pd.DataFrame(grid.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=600, objective='multi:softmax',\n",
    "                    silent=False, nthread=-1, max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42min 53s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=15,\n",
       "              min_child_weight=1, missing=None, n_estimators=600, n_jobs=1,\n",
       "              nthread=-1, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=False, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time xgb.fit(X_train, y_train-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_XGBC = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400168836816658"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f1_score(y_test, y_pred_XGBC+1, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex_geo = test_values.drop(['geo_level_1_id','geo_level_2_id','geo_level_3_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test_ex_geo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(DATA_DIR / 'submission_format.csv', index_col='building_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.DataFrame(data=y_pred,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.damage_grade = my_submission.damage_grade.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Ensemble submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex_geo = test_values.drop(['geo_level_1_id','geo_level_2_id','geo_level_3_id'], axis=1)\n",
    "test_small = test_values[cols_to_use]\n",
    "test_xgb = xgb.DMatrix(test_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_full = clf.predict_proba(test_ex_geo)   \n",
    "y_pred_rf_small = clf1.predict_proba(test_small)\n",
    "y_pred_xg_small = clfXGB.predict_proba(test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.mean([y_pred_rf_full,y_pred_rf_small,y_pred_xg_small], axis=0)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
